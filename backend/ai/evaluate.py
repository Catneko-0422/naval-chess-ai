import torch
import numpy as np
from battleship_board import generate_board
from env import BattleshipEnv
from dqn_battleship import DQN, BOARD_SIZE, get_allowed_actions

board = generate_board()['board']

def print_board(board, title="æ£‹ç›¤"):
    print(f"\nğŸ“˜ {title}")
    for row in board:
        print(" ".join(str(cell) for cell in row))
    print()

def evaluate(model_path="dqn_battleship.pth", board=generate_board()['board'], episodes=10):
    model = DQN()
    model.load_state_dict(torch.load(model_path))
    model.eval()
    env = BattleshipEnv(board)
    env.ship_board = board
    total_steps = []
    for ep in range(episodes):
        state_feature = env.reset()
        done = False
        steps = 0
        print(f"\nğŸ® --- Episode {ep+1} ---")
        print_board(env.ship_board, title="éš±è—èˆ¹è‰¦æ£‹ç›¤ï¼ˆ1 è¡¨ç¤ºèˆ¹ï¼Œåƒ…ä¾›åƒè€ƒï¼‰")
        while not done:
            allowed_moves = get_allowed_actions(env)
            state_tensor = torch.FloatTensor(state_feature).unsqueeze(0)
            with torch.no_grad():
                q_values = model(state_tensor).squeeze()
                for i in range(BOARD_SIZE * BOARD_SIZE):
                    if i not in allowed_moves:
                        q_values[i] = -1e9
                action = torch.argmax(q_values).item()
            x, y = divmod(action, BOARD_SIZE)
            print(f"ğŸ” Step {steps+1}: AI æ”»æ“Šåº§æ¨™ ({x}, {y})")
            state_feature, reward, done = env.step(action)
            print_board(env.state, title="ç›®å‰éŠæˆ²ç‹€æ…‹ï¼ˆ0: æœªæ”»æ“Š, 1: æœªå‘½ä¸­, 2: å‘½ä¸­, 3: æ²ˆæ²’ï¼‰")
            steps += 1
        total_steps.append(steps)
        print(f"âœ… æœ¬å±€å®Œæˆï¼Œå…± {steps} æ­¥")
    avg_steps = sum(total_steps) / episodes
    print(f"\nâœ¨ å¹³å‡å®Œæˆæ­¥æ•¸ï¼š{avg_steps:.2f} æ­¥")

if __name__ == "__main__":
    evaluate("dqn_battleship.pth", generate_board()['board'], 1)
